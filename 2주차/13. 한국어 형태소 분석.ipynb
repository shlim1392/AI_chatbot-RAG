{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d87e2f2",
   "metadata": {},
   "source": [
    "# **한국어 형태소 분석**\n",
    "\n",
    "### 1. 형태소 분석이란?\n",
    "\n",
    "> 형태소(morpheme): 의미를 가지는 가장 작은 단위\n",
    "> \n",
    "> 예:\n",
    "> \n",
    "> - “재미있었다” → `재미 / 있 / 었 / 다`\n",
    "> - “배송이 빠르네요” → `배송 / 이 / 빠르 / 네요`\n",
    "\n",
    "|구분|영어(Word Tokenization)|한국어(형태소 분석)|\n",
    "|---|---|---|\n",
    "|단어 단위|공백 기준 분리 가능|조사, 어미 등 때문에 복잡|\n",
    "|예시|“I love movie” → [I, love, movie]|“영화를 좋아한다” → [영화, 를, 좋아, 한다]|\n",
    "|문제점|없음|“좋아”, “좋아요”, “좋았다” → 형태가 다름|\n",
    "\n",
    "👉 따라서 한국어에서는 **형태소 분석기**를 이용해야 문장을 올바르게 나눌 수 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧩 2. Okt(Open Korean Text) 소개\n",
    "\n",
    "|항목|설명|\n",
    "|---|---|\n",
    "|**이름**|Open Korean Text (구 Twitter 한국어 분석기)|\n",
    "|**제공 모듈**|`konlpy.tag.Okt()`|\n",
    "|**특징**|한국어 문장을 형태소 단위로 나누고, 품사 태깅 및 어간(stem) 추출 가능|\n",
    "|**자주 사용하는 메서드**|`.morphs()`, `.pos()`, `.nouns()`|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66af2168",
   "metadata": {},
   "source": [
    "> 유사한 하위호환  mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1831815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 형태소: ['이', '영화', '는', '정말', '재미있고', '감동', '적', '이었어요', '!']\n",
      "🔹 명사만: ['이', '영화', '정말', '감동']\n",
      "🔹 품사 태깅: [('이', 'Noun'), ('영화', 'Noun'), ('는', 'Josa'), ('정말', 'Noun'), ('재미있고', 'Adjective'), ('감동', 'Noun'), ('적', 'Suffix'), ('이었어요', 'Verb'), ('!', 'Punctuation')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "sentence = \"이 영화는 정말 재미있고 감동적이었어요!\"\n",
    "print(\"🔹 형태소:\", okt.morphs(sentence))\n",
    "print(\"🔹 명사만:\", okt.nouns(sentence))\n",
    "print(\"🔹 품사 태깅:\", okt.pos(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45346031",
   "metadata": {},
   "source": [
    "###  3. 불용어 제거 + 어간 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5098949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 전처리 전: 이 영화는 정말 재미있고 감동적이었어요!\n",
      "✅ 전처리 후: 영화 정말 재미있다 감동\n"
     ]
    }
   ],
   "source": [
    "stopwords = ['은','는','이','가','을','를','에','의','와','과',\n",
    "             '도','으로','로','에서','라','하다','있다','되다','이다','그','저','것']\n",
    "\n",
    "def tokenize_korean(text):\n",
    "    tokens = okt.morphs(str(text), stem=True)        # 어간추출(stem=True)\n",
    "    tokens = [w for w in tokens if w not in stopwords and len(w) > 1]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "sample = \"이 영화는 정말 재미있고 감동적이었어요!\"\n",
    "print(\"✅ 전처리 전:\", sample)\n",
    "print(\"✅ 전처리 후:\", tokenize_korean(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b29f911b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 단어 목록: ['감동' '너무' '배우' '스토리' '연기' '영화' '음악' '이에요' '재미있다' '정말' '지루하다' '최악']\n",
      "\\n✅ 변환된 TF-IDF 행렬:\\n [[0.         0.         0.         0.         0.         0.57735027\n",
      "  0.         0.         0.57735027 0.57735027 0.         0.        ]\n",
      " [0.         0.         0.5        0.         0.5        0.\n",
      "  0.         0.5        0.         0.         0.         0.5       ]\n",
      " [0.70710678 0.         0.         0.         0.         0.\n",
      "  0.70710678 0.         0.         0.         0.         0.        ]\n",
      " [0.         0.57735027 0.         0.57735027 0.         0.\n",
      "  0.         0.         0.         0.         0.57735027 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 샘플 데이터\n",
    "data = [\n",
    "    \"이 영화 정말 재미있어요\",\n",
    "    \"배우 연기가 최악이에요\",\n",
    "    \"음악이 감동적이었어요\",\n",
    "    \"스토리가 너무 지루했어요\",\n",
    "]\n",
    "\n",
    "# 1️⃣ 형태소 분석 및 정제\n",
    "tokenized = [tokenize_korean(t) for t in data]\n",
    "\n",
    "# 2️⃣ TF-IDF 변환\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_vec = vectorizer.fit_transform(tokenized)\n",
    "\n",
    "print(\"✅ 단어 목록:\", vectorizer.get_feature_names_out())\n",
    "print(\"\\\\n✅ 변환된 TF-IDF 행렬:\\\\n\", X_vec.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b595e212",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
