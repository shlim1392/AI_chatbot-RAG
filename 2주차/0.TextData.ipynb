{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de247e16",
   "metadata": {},
   "source": [
    "# 0. í…ìŠ¤íŠ¸ë°ì´í„°\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ef5df3",
   "metadata": {},
   "source": [
    "## íŒŒì´ì¬ ê¸°ë³¸ ë‚´ì¥ í•¨ìˆ˜\n",
    "### 1. len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7378441e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "s = \"ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ë„ˆë¬´ ì¶¥ìŠµë‹ˆë‹¤. ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”.\"\n",
    "# ê³µë°±ì„ í¬í•¨í•œ ëª¨ë“  í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì§‘ê³„\n",
    "print(len(s))\n",
    "\n",
    "tokens = [\"ì˜¤ëŠ˜\", \"ë‚ ì”¨\", \"ë„ˆë¬´\", \"ì¶¥ìŠµë‹ˆë‹¤\", \"ì¢‹ì€\", \"í•˜ë£¨\",\"ë˜ì„¸ìš”\"]\n",
    "# ì˜ë¯¸ ì¤‘ì‹¬ì˜ êµ¬ë‘ì , ê³µë°±ì„ ìµœëŒ€í•œ ì œê±°í•œ ë‚´ìš©ì„ í† í°ìœ¼ë¡œ ì„¤ì •\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b789e61f",
   "metadata": {},
   "source": [
    "### 2. split()\n",
    "- ëŒ€í‘œì ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ í† í°í™” ì‹œí‚¤ëŠ” ê°€ì¥ ê¸°ë³¸ì ì¸ ë©”ì„œë“œ(ê¸°ëŠ¥)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074f37ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ì˜¤ëŠ˜', 'ë‚ ì”¨ê°€', 'ì •ë§', 'ì¶”ì›Œìš”']\n",
      "['ì‚¬ê³¼', 'í¬ë„', 'ë°°']\n",
      "['ì‚¬ê³¼', 'í¬ë„,ë°°']\n"
     ]
    }
   ],
   "source": [
    "s = \"   ì˜¤ëŠ˜     ë‚ ì”¨ê°€    ì •ë§    ì¶”ì›Œìš”\"\n",
    "print(s.split())\n",
    "\n",
    "#\",\"ë¡œ êµ¬ë¶„ë˜ì–´ìˆëŠ” ë¬¸ì¥ì„ í† í°í™”\n",
    "print(\"ì‚¬ê³¼,í¬ë„,ë°°\".split(\",\"))\n",
    "\n",
    "\n",
    "## maxsplit ë¶„í•  íšŸìˆ˜ ì œí•œ ê¸°ëŠ¥\n",
    "print(\"ì‚¬ê³¼,í¬ë„,ë°°\".split(\",\", maxsplit=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fca206",
   "metadata": {},
   "source": [
    "## 3. set()\n",
    "\n",
    "- ì¤‘ë³µì„ ì œê±°í•˜ëŠ” êµ¬ë¬¸(ê³ ìœ ë‹¨ì–´ ì§‘í•©)\n",
    "- í† í°ì— ëŒ€í•œ ì „ì²´ ë¦¬ìŠ¤íŠ¸ ì¤‘ì— ì¤‘ë³µëœ ë‹¨ì–´ë¥¼ ì œê±°í•˜ëŠ” êµ¬ë¬¸\n",
    "\n",
    ">> set : ìë£Œêµ¬ì¡° tuple()\n",
    ">> íŠ¹ì§• : ìˆ˜í•™ì§‘í•© (ì •ë ¬ì„ í•  ìˆ˜ ì—†ìŒ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e61df7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ì •ë§', 'ì˜¤ëŠ˜', 'ì¢‹ì•„ìš”', 'ë‚ ì”¨ê°€'}\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "tokens = [\"ì˜¤ëŠ˜\", \"ë‚ ì”¨ê°€\", \"ì •ë§\", \"ì¢‹ì•„ìš”\", \"ì •ë§\"]\n",
    "vocab = set(tokens)\n",
    "print(vocab)          # {'ì •ë§', 'ì¢‹ì•„ìš”', 'ì˜¤ëŠ˜', 'ë‚ ì”¨ê°€'}\n",
    "print(len(vocab))\n",
    "print(len(tokens))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2ae90a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  ì‹¤ë¬´ì—ì„œ ë°”ë¡œ ì“°ëŠ” ê·œì¹™(ì…ë¬¸ ë²„ì „)\n",
    "\n",
    "> - **ì†Œë¬¸ìí™”**: ì˜ë¬¸ í…ìŠ¤íŠ¸ëŠ” `lower()`ë¡œ ëŒ€ì†Œë¬¸ì ë³€í˜•ì„ í†µì¼.\n",
    "> - **ì•ë’¤ ê³µë°± ì œê±°**: `strip()`ìœ¼ë¡œ ì…ë ¥ í”ë“¤ë¦¼ ìµœì†Œí™”.\n",
    "> - **êµ¬ë‘ì  ì²˜ë¦¬**: ì´ˆë³´ìëŠ” ìš°ì„  `split()` ê¸°ë°˜ìœ¼ë¡œ ì‹œì‘ â†’ ì´í›„ ì •ê·œì‹/í† í¬ë‚˜ì´ì €ë¡œ ê°œì„ .\n",
    ">- **ê²°ì¸¡/ë¹ˆë¬¸ì ì²˜ë¦¬**: ë¹ˆ ë¬¸ìì—´ì€ ê±´ë„ˆë›°ê±°ë‚˜ ë¡œê¹….\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b256e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World\n",
      "   hello, world    \n",
      "hello, world\n"
     ]
    }
   ],
   "source": [
    "# 1. strip() / lower()\n",
    "# stripì€ ì–‘ìª½ ê³µë°±ì„ ì œê±°\n",
    "# lowerëŠ” ëª¨ë“  ë¬¸ìë¥¼ ì†Œë¬¸ìí™”\n",
    "\n",
    "s = \"   Hello, World    \"\n",
    "\n",
    "clean1 = s.strip()\n",
    "clean2 = s.lower()\n",
    "clean3 = s.strip().lower()\n",
    "\n",
    "print(clean1)\n",
    "print(clean2)\n",
    "print(clean3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32a6450b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-18  ê¹€ì² ìˆ˜  ì œí’ˆA  êµ¬ë§¤ì™„ë£Œ  ì„œìš¸\n"
     ]
    }
   ],
   "source": [
    "# csv íŒŒì¼ í•œì¤„ì„ ì•ˆì „í•˜ê²Œ êµ¬ë¶„í•˜ê¸°\n",
    "# CSV = COMMA Separated Values\n",
    "\n",
    "row = \"2025-10-18, ê¹€ì² ìˆ˜, ì œí’ˆA, êµ¬ë§¤ì™„ë£Œ, ì„œìš¸\"\n",
    "cols = row.split(\",\")\n",
    "date, name, product, status, location = cols[0], cols[1], cols[2], cols[3], cols[4]\n",
    "print(date, name, product, status, location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eb54ab",
   "metadata": {},
   "source": [
    "---\n",
    "## **ì‹¤ìŠµ**\n",
    "\n",
    "text = \"íŒŒì´ì¬ í…ìŠ¤íŠ¸ ë¶„ì„ ì‹œì‘!   ê³µë°±ê³¼, êµ¬ë‘ì ì„ ê´€ì°°í•©ë‹ˆë‹¤...\"\n",
    "\n",
    "1) ê¸°ë³¸ë‚˜ëˆ„ê¸°\n",
    "2) ê³ ìœ ë‹¨ì–´ ì§‘í•©\n",
    "3) ì œëª©/ë³¸ë¬¸ ë¶„ë¦¬\n",
    "4) ì—¬ëŸ¬ì¤„ ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c678c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['íŒŒì´ì¬', 'í…ìŠ¤íŠ¸', 'ë¶„ì„', 'ì‹œì‘!', 'ê³µë°±ê³¼,', 'êµ¬ë‘ì ì„', 'ê´€ì°°í•©ë‹ˆë‹¤...']\n",
      "í† í°ìˆ˜ 7\n",
      "{'ê³µë°±ê³¼,', 'ë¶„ì„', 'êµ¬ë‘ì ì„', 'ê´€ì°°í•©ë‹ˆë‹¤...', 'í…ìŠ¤íŠ¸', 'ì‹œì‘!', 'íŒŒì´ì¬'}\n",
      "ì–´íœ˜ í¬ê¸° 7\n",
      "ì œëª©: ì…ë¬¸ ìˆ˜ì—… ì•ˆë‚´   ë³¸ë¬¸: ì˜¤ëŠ˜ì€ ë¬¸ìì—´ ê¸°ë³¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.\n",
      "ì¤„ ìˆ˜: 4 | ë‚´ìš©: ['ì²«ì§¸ ì¤„', 'ë‘˜ì§¸ ì¤„', '', 'ë„·ì§¸ ì¤„']\n"
     ]
    }
   ],
   "source": [
    "text = \"íŒŒì´ì¬ í…ìŠ¤íŠ¸ ë¶„ì„ ì‹œì‘!   ê³µë°±ê³¼, êµ¬ë‘ì ì„ ê´€ì°°í•©ë‹ˆë‹¤...\"\n",
    "\n",
    "# 1) ê¸°ë³¸ë‚˜ëˆ„ê¸°\n",
    "tokens = text.split()\n",
    "print(tokens)\n",
    "print(f\"í† í°ìˆ˜ {len(tokens)}\")\n",
    "\n",
    "# 2) ê³ ìœ ë‹¨ì–´ ì§‘í•©\n",
    "vocab = set(tokens)\n",
    "print(vocab)\n",
    "print(f\"ì–´íœ˜ í¬ê¸° {len(vocab)}\")\n",
    "\n",
    "# 3) ì œëª©/ë³¸ë¬¸ ë¶„ë¦¬\n",
    "msg = \"ì œëª©: ì…ë¬¸ ìˆ˜ì—… ì•ˆë‚´ - ë³¸ë¬¸: ì˜¤ëŠ˜ì€ ë¬¸ìì—´ ê¸°ë³¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.\"\n",
    "sen = msg.split(\"-\")\n",
    "title, content = sen[0], sen[1]\n",
    "print(title, content)\n",
    "\n",
    "# 4) ì—¬ëŸ¬ì¤„ ì²˜ë¦¬\n",
    "multi = \"ì²«ì§¸ ì¤„\\në‘˜ì§¸ ì¤„\\n\\në„·ì§¸ ì¤„\"\n",
    "lines = multi.splitlines()\n",
    "print(\"ì¤„ ìˆ˜:\", len(lines), \"| ë‚´ìš©:\", lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6de1a71",
   "metadata": {},
   "source": [
    "## **ì‹¤ìŠµ2**\n",
    "\n",
    "1. ê¸°ë³¸ `split()` ê²°ê³¼ í† í° ìˆ˜\n",
    "2. `set()` ì–´íœ˜ í¬ê¸°\n",
    "3. ê°€ì¥ ê¸´ í† í°ê³¼ ê¸¸ì´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83274287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ì§€ê¸ˆì˜', 'ì†ë„ê°€', 'ì•„ë¬´ë¦¬', 'ëŠë ¤ë„,', 'ë©ˆì¶”ì§€ë§Œ', 'ì•Šìœ¼ë©´', 'ê´œì°®ë‹¤.', 'ì™„ë²½ì„', 'ë‘ë ¤ì›Œí•˜ì§€', 'ë§ˆë¼.', 'ì™„ë²½ì—ëŠ”', 'ë„ë‹¬í• ', 'ìˆ˜', 'ì—†ì§€ë§Œ,', 'ê·¸ê±¸', 'í–¥í•´', 'ë‚˜ì•„ê°€ë©´', 'íƒì›”í•¨ì—', 'ë‹¿ëŠ”ë‹¤.', 'ë°©í–¥ì„', 'ìƒì—ˆë‹¤ê³ ', 'í•´ì„œ', 'ê¸¸ì„', 'ìƒì€', 'ê±´', 'ì•„ë‹ˆë‹¤.', 'ìì‹ ì„', 'ë¯¿ì§€', 'ëª»í•œë‹¤ë©´,', 'ì•„ë¬´ë„', 'ë‹¹ì‹ ì„', 'ë¯¿ì§€', 'ëª»í•œë‹¤.'], \n",
      " í† í°ìˆ˜ : 33\n",
      "{'ë©ˆì¶”ì§€ë§Œ', 'ë‘ë ¤ì›Œí•˜ì§€', 'ë‹¿ëŠ”ë‹¤.', 'ì™„ë²½ì„', 'ëª»í•œë‹¤ë©´,', 'ê¸¸ì„', 'ìˆ˜', 'ì•„ë¬´ë¦¬', 'ë§ˆë¼.', 'ì§€ê¸ˆì˜', 'ê´œì°®ë‹¤.', 'ëª»í•œë‹¤.', 'ê·¸ê±¸', 'ë‚˜ì•„ê°€ë©´', 'ì•„ë‹ˆë‹¤.', 'ì†ë„ê°€', 'ì•„ë¬´ë„', 'ëŠë ¤ë„,', 'ìì‹ ì„', 'íƒì›”í•¨ì—', 'ë‹¹ì‹ ì„', 'ë°©í–¥ì„', 'ë„ë‹¬í• ', 'ìƒì—ˆë‹¤ê³ ', 'ì—†ì§€ë§Œ,', 'í•´ì„œ', 'ì•Šìœ¼ë©´', 'í–¥í•´', 'ê±´', 'ìƒì€', 'ë¯¿ì§€', 'ì™„ë²½ì—ëŠ”'}\n",
      " ì–´íœ˜ ìˆ˜ :32\n",
      "ê°€ì¥ ê¸´ í† í°: ë‘ë ¤ì›Œí•˜ì§€ | ê¸¸ì´: 5\n"
     ]
    }
   ],
   "source": [
    "text = \"ì§€ê¸ˆì˜ ì†ë„ê°€ ì•„ë¬´ë¦¬ ëŠë ¤ë„, ë©ˆì¶”ì§€ë§Œ ì•Šìœ¼ë©´ ê´œì°®ë‹¤. ì™„ë²½ì„ ë‘ë ¤ì›Œí•˜ì§€ ë§ˆë¼. ì™„ë²½ì—ëŠ” ë„ë‹¬í•  ìˆ˜ ì—†ì§€ë§Œ, ê·¸ê±¸ í–¥í•´ ë‚˜ì•„ê°€ë©´ íƒì›”í•¨ì— ë‹¿ëŠ”ë‹¤. ë°©í–¥ì„ ìƒì—ˆë‹¤ê³  í•´ì„œ ê¸¸ì„ ìƒì€ ê±´ ì•„ë‹ˆë‹¤. ìì‹ ì„ ë¯¿ì§€ ëª»í•œë‹¤ë©´, ì•„ë¬´ë„ ë‹¹ì‹ ì„ ë¯¿ì§€ ëª»í•œë‹¤.\"\n",
    "\n",
    "\n",
    "# split()\n",
    "tokens = text.split()\n",
    "print(f\"{tokens}, \\n í† í°ìˆ˜ : {len(tokens)}\")\n",
    "\n",
    "# set()\n",
    "vocab = set(tokens)\n",
    "print(f\"{vocab}\\n ì–´íœ˜ ìˆ˜ :{len(vocab)}\")\n",
    "\n",
    "# ê°€ì¥ ê¸´ í† í°ê³¼ ê¸¸ì´\n",
    "longest = max(tokens, key=len) if tokens else \"\"\n",
    "print(\"ê°€ì¥ ê¸´ í† í°:\", longest, \"| ê¸¸ì´:\", len(longest))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef358c4d",
   "metadata": {},
   "source": [
    "---\n",
    "## **í™œìš© ì»´í”„ë¦¬í—¨ì…˜**\n",
    "\n",
    "### 1. `apply()` í•¨ìˆ˜ë€?\n",
    "\n",
    "#### ğŸ”¹ ê°œë…\n",
    "\n",
    "`pandas`ì˜ `apply()`ëŠ” **DataFrame ë˜ëŠ” Seriesì˜ ê° ì›ì†Œì— í•¨ìˆ˜ë¥¼ ì ìš©**í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë£¨í”„(`for`)ë¥¼ ëŒë¦¬ì§€ ì•Šê³  í•œ ì¤„ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆì–´ íš¨ìœ¨ì ì…ë‹ˆë‹¤.\n",
    "\n",
    "```python\n",
    "df[\"cleaned\"] = df[\"review\"].apply(clean_text)\n",
    "\n",
    "```\n",
    "\n",
    "â¡ï¸ `\"review\"` ì—´ì˜ ê° í–‰ì— `clean_text()` í•¨ìˆ˜ë¥¼ ì ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ğŸ”¹ ì‘ë™ êµ¬ì¡°\n",
    "\n",
    "| ì½”ë“œ | ì˜ë¯¸ |\n",
    "| --- | --- |\n",
    "| `df[\"col\"].apply(func)` | Series(ì—´)ì˜ ê° ì›ì†Œì— `func()`ë¥¼ ì ìš© |\n",
    "| `df.apply(func, axis=1)` | í–‰(row) ë‹¨ìœ„ë¡œ í•¨ìˆ˜ ì ìš© |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95a56889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        text  len\n",
      "0        ë°ì´í„°    3\n",
      "1         AI    2\n",
      "2  Python ê³µë¶€    9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"text\": [\"ë°ì´í„°\", \"AI\", \"Python ê³µë¶€\"]})\n",
    "df[\"len\"] = df[\"text\"].apply(len)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9de9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    2\n",
       "2    9\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ()ê°€ í•„ìš”ì—†ìŒ_ê¸°ë³¸ë§¤ì„œë“œì¼ ê²½ìš°\n",
    "df['text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6ee1df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>len</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ë°ì´í„°</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AI</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Python ê³µë¶€</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text  len  word_count\n",
       "0        ë°ì´í„°    3           1\n",
       "1         AI    2           1\n",
       "2  Python ê³µë¶€    9           2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def word_count(text):\n",
    "    return len(text.split())\n",
    "\n",
    "df['word_count'] = df['text'].apply(word_count)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394687a0",
   "metadata": {},
   "source": [
    "## 2. `lambda` í•¨ìˆ˜\n",
    "\n",
    "### ğŸ”¹ ê°œë…\n",
    "\n",
    "`lambda`ëŠ” í•œ ì¤„ì§œë¦¬ ìµëª… í•¨ìˆ˜(ì´ë¦„ ì—†ëŠ” í•¨ìˆ˜)ë¥¼ ë§Œë“¤ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "`def`ë¥¼ ì“°ì§€ ì•Šê³  ê°„ë‹¨í•œ ê³„ì‚°ì‹ì´ë‚˜ ë³€í™˜ì‹ì— ìì£¼ ì‚¬ìš©ë©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f29f71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        text  len  word_count\n",
      "0        ë°ì´í„°    3           1\n",
      "1         AI    2           1\n",
      "2  Python ê³µë¶€    9           2\n"
     ]
    }
   ],
   "source": [
    "df[\"len\"] = df[\"text\"].apply(lambda x: len(x))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97284f77",
   "metadata": {},
   "source": [
    "## 3. ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜ (List Comprehension)\n",
    "\n",
    "### ğŸ”¹ ê°œë…\n",
    "\n",
    "ë°˜ë³µë¬¸(`for`)ì„ í•œ ì¤„ë¡œ ê°„ê²°í•˜ê²Œ í‘œí˜„í•˜ëŠ” íŒŒì´ì¬ ë¬¸ë²•.\n",
    "\n",
    "> \"ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì§§ì€ ë¬¸ë²•\"\n",
    "### ğŸ”¹ ê¸°ë³¸ êµ¬ì¡°\n",
    "\n",
    "```python\n",
    "[í‘œí˜„ì‹ for ë³€ìˆ˜ in ë¦¬ìŠ¤íŠ¸]\n",
    "\n",
    "```\n",
    "\n",
    "í•„í„°ë¥¼ ì¶”ê°€í•˜ê³  ì‹¶ì„ ë•Œ:\n",
    "\n",
    "```python\n",
    "[í‘œí˜„ì‹ for ë³€ìˆ˜ in ë¦¬ìŠ¤íŠ¸ if ì¡°ê±´ì‹]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "576f0d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'science', 'ai']\n"
     ]
    }
   ],
   "source": [
    "words = ['Data', 'Science', 'AI']\n",
    "lower_words = [w.lower() for w in words]\n",
    "print(lower_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "57567192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ë°ì´í„°', 'ë¶„ì„', 'ë„ˆë¬´', 'ì¢‹ì•„ìš”'], ['ì˜¤ëŠ˜ì˜', 'ë‚ ì”¨ëŠ”', 'ë§‘ìŒ']]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "sample = [\"ë°ì´í„°!! ë¶„ì„ ë„ˆë¬´ ì¢‹ì•„ìš” ğŸ’•\", \"   ì˜¤ëŠ˜ì˜ ë‚ ì”¨ëŠ” ë§‘ìŒ!   \"]\n",
    "\n",
    "# ëŒë‹¤\n",
    "clean = lambda x : re.sub(r'[^ã„±-ã…ê°€-í£a-zA-Z09]',' ',x).split()\n",
    "cleaned = [clean(t) for t in sample]\n",
    "print(cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e2b415e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4]\n"
     ]
    }
   ],
   "source": [
    "# ì¡°ê±´ì„ í¬í•¨í•œ ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "nums = [1,2,3,4,5]\n",
    "even = [n for n in nums if n %2 ==0]\n",
    "\n",
    "print(even)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b4107f",
   "metadata": {},
   "source": [
    "## **ì‹¤ìŠµ**\n",
    "\n",
    "- ì¿ íŒ¡ ë¦¬ë·° ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "81bd77d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"review\" : [\n",
    "        \"í•˜ë£¨ í•œí¬ ë³´ì¥ê· ìˆ˜ 20ì–µ ì¶©ë¶„í•œ ìœ ì‚°ê· !\",\n",
    "        \"ë¯¿ì„ ìˆ˜ ìˆëŠ” ë¸Œëœë“œ!\",\n",
    "        \"ì•„ì—°í•¨ìœ ë¡œ ë©´ì—­ë„ ì±™ê¸¸ ìˆ˜ ìˆì–´ìš”!\",\n",
    "        \"ëª¨ìœ  ìœ ë˜ ì›ë£Œ í•¨ìœ !\",\n",
    "        \"ì´ëŸ°ë¶„ê»˜ ì¶”ì²œ 1. ì„ì‹  ì¤‘ ë°°ë³€í™œë™ì´ ì›í™œí•˜ì§€ ì•Šì€ ë¶„ 2. ë³µë¶€ë¶ˆí¸ê°ê³¼ ë³€ë¹„ë¡œ ë¶ˆí¸í•˜ì‹  ë¶„ 3. ë©´ì—­ê¸°ëŠ¥ì´ í•„ìš”í•˜ì‹  ì„ì‚°ë¶€ ë° ìˆ˜ìœ ë¶€\",\n",
    "        \"ë²Œì¨ ë§Œì‚­ì„ í–¥í•´ê°€ëŠ” ì™€ì´í”„ë¥¼ ìœ„í•´ ì£¼ë¬¸í–ˆì–´ìš”.\",\n",
    "        \" ìš”ì¦˜ í™”ì¥ì‹¤ë„ ìì£¼ ëª»ê°€ê³ <br>ë”ë¶€ë£© í•˜ë‹¤ê³  í•˜ë”ë¼êµ¬ìš”. ì„ì‚°ë¶€ëŠ” ìœ ì‚°ê· ì´ í•„ìˆ˜ì¸ë° ë’¤ëŠ¦ê²Œë¼ë„ ì±™ê²¨ë³´ë ¤ê³  ê¸‰íˆ ì£¼ë¬¸í–ˆìŠµë‹ˆë‹¤!\",\n",
    "        \"í•˜ë‚˜ì”© íœ´ëŒ€í•˜ê¸°ë„ ì¢‹ê²Œ ë˜ì–´ìˆì–´ì„œ ì—¬í–‰ì´ë‚˜ ì™¸ì¶œí• ë•Œ ì£¼ë¨¸ë‹ˆì— ì™ì™ ì±™ê²¨ë‹¤ë‹ˆê¸° ì¢‹ì•˜ë‹µë‹ˆë‹¤.\" ,\n",
    "        \"ì•Œì•½ íƒ€ì…ì´ ì•„ë‹Œ ë¶„ë§í˜•ì´ë¼ì„œ ë¬¼ ì—†ì´ ê·¸ëƒ¥ í†¡ í„¸ì–´ë„£ê¸°ì—ë„ ì¥ì†Œì œì•½ë„ ì—†ê³  ë¶€ë‹´ì´ ì—†ë”ë¼êµ¬ìš© ã…ã…\",\n",
    "        \"ì•„ì—°ë„ ë“¤ì–´ìˆì–´ì„œ ë” ê±´ê°•í•´ì§€ëŠ” ëŠë‚Œì´ì—ìš” ã…ã…\",\n",
    "        \"ë¯¿ê³  ë¨¹ì„ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤!\" ,\n",
    "        \"ì•ìœ¼ë¡œ ê¾¸ì¤€íˆ ì´ê±¸ë¡œ ì •ì°©í•´ì„œ ë³€ë¹„íƒˆì¶œ í•˜ë ¤ê³  í•´ìš” ã…ã…ë§Œì¡±í•©ë‹ˆë‹¤!!\",\n",
    "    ]\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "450eb997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "clean = lambda x: re.sub(r'[^ã„±-ã…ê°€-í£a-zA-Z0-9\\s]', ' ', x).split()\n",
    "\n",
    "df[\"tokens\"] = df[\"review\"].apply(clean)\n",
    "df[\"word_count\"] = df[\"tokens\"].apply(len)\n",
    "df[\"vocab_count\"] = df[\"tokens\"].apply(lambda x: len(set(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b38e70e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word_count</th>\n",
       "      <th>vocab_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>í•˜ë£¨ í•œí¬ ë³´ì¥ê· ìˆ˜ 20ì–µ ì¶©ë¶„í•œ ìœ ì‚°ê· !</td>\n",
       "      <td>[í•˜ë£¨, í•œí¬, ë³´ì¥ê· ìˆ˜, 20ì–µ, ì¶©ë¶„í•œ, ìœ ì‚°ê· ]</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ë¯¿ì„ ìˆ˜ ìˆëŠ” ë¸Œëœë“œ!</td>\n",
       "      <td>[ë¯¿ì„, ìˆ˜, ìˆëŠ”, ë¸Œëœë“œ]</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ì•„ì—°í•¨ìœ ë¡œ ë©´ì—­ë„ ì±™ê¸¸ ìˆ˜ ìˆì–´ìš”!</td>\n",
       "      <td>[ì•„ì—°í•¨ìœ ë¡œ, ë©´ì—­ë„, ì±™ê¸¸, ìˆ˜, ìˆì–´ìš”]</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ëª¨ìœ  ìœ ë˜ ì›ë£Œ í•¨ìœ !</td>\n",
       "      <td>[ëª¨ìœ , ìœ ë˜, ì›ë£Œ, í•¨ìœ ]</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ì´ëŸ°ë¶„ê»˜ ì¶”ì²œ 1. ì„ì‹  ì¤‘ ë°°ë³€í™œë™ì´ ì›í™œí•˜ì§€ ì•Šì€ ë¶„ 2. ë³µë¶€ë¶ˆí¸ê°ê³¼ ë³€ë¹„ë¡œ ...</td>\n",
       "      <td>[ì´ëŸ°ë¶„ê»˜, ì¶”ì²œ, 1, ì„ì‹ , ì¤‘, ë°°ë³€í™œë™ì´, ì›í™œí•˜ì§€, ì•Šì€, ë¶„, 2, ë³µë¶€...</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ë²Œì¨ ë§Œì‚­ì„ í–¥í•´ê°€ëŠ” ì™€ì´í”„ë¥¼ ìœ„í•´ ì£¼ë¬¸í–ˆì–´ìš”.</td>\n",
       "      <td>[ë²Œì¨, ë§Œì‚­ì„, í–¥í•´ê°€ëŠ”, ì™€ì´í”„ë¥¼, ìœ„í•´, ì£¼ë¬¸í–ˆì–´ìš”]</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ìš”ì¦˜ í™”ì¥ì‹¤ë„ ìì£¼ ëª»ê°€ê³ &lt;br&gt;ë”ë¶€ë£© í•˜ë‹¤ê³  í•˜ë”ë¼êµ¬ìš”. ì„ì‚°ë¶€ëŠ” ìœ ì‚°ê· ì´ í•„ìˆ˜...</td>\n",
       "      <td>[ìš”ì¦˜, í™”ì¥ì‹¤ë„, ìì£¼, ëª»ê°€ê³ , br, ë”ë¶€ë£©, í•˜ë‹¤ê³ , í•˜ë”ë¼êµ¬ìš”, ì„ì‚°ë¶€ëŠ”,...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>í•˜ë‚˜ì”© íœ´ëŒ€í•˜ê¸°ë„ ì¢‹ê²Œ ë˜ì–´ìˆì–´ì„œ ì—¬í–‰ì´ë‚˜ ì™¸ì¶œí• ë•Œ ì£¼ë¨¸ë‹ˆì— ì™ì™ ì±™ê²¨ë‹¤ë‹ˆê¸° ì¢‹ì•˜ë‹µë‹ˆë‹¤.</td>\n",
       "      <td>[í•˜ë‚˜ì”©, íœ´ëŒ€í•˜ê¸°ë„, ì¢‹ê²Œ, ë˜ì–´ìˆì–´ì„œ, ì—¬í–‰ì´ë‚˜, ì™¸ì¶œí• ë•Œ, ì£¼ë¨¸ë‹ˆì—, ì™ì™, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ì•Œì•½ íƒ€ì…ì´ ì•„ë‹Œ ë¶„ë§í˜•ì´ë¼ì„œ ë¬¼ ì—†ì´ ê·¸ëƒ¥ í†¡ í„¸ì–´ë„£ê¸°ì—ë„ ì¥ì†Œì œì•½ë„ ì—†ê³  ë¶€ë‹´ì´...</td>\n",
       "      <td>[ì•Œì•½, íƒ€ì…ì´, ì•„ë‹Œ, ë¶„ë§í˜•ì´ë¼ì„œ, ë¬¼, ì—†ì´, ê·¸ëƒ¥, í†¡, í„¸ì–´ë„£ê¸°ì—ë„, ì¥ì†Œ...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ì•„ì—°ë„ ë“¤ì–´ìˆì–´ì„œ ë” ê±´ê°•í•´ì§€ëŠ” ëŠë‚Œì´ì—ìš” ã…ã…</td>\n",
       "      <td>[ì•„ì—°ë„, ë“¤ì–´ìˆì–´ì„œ, ë”, ê±´ê°•í•´ì§€ëŠ”, ëŠë‚Œì´ì—ìš”, ã…ã…]</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ë¯¿ê³  ë¨¹ì„ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤!</td>\n",
       "      <td>[ë¯¿ê³ , ë¨¹ì„, ìˆ˜, ìˆì—ˆìŠµë‹ˆë‹¤]</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ì•ìœ¼ë¡œ ê¾¸ì¤€íˆ ì´ê±¸ë¡œ ì •ì°©í•´ì„œ ë³€ë¹„íƒˆì¶œ í•˜ë ¤ê³  í•´ìš” ã…ã…ë§Œì¡±í•©ë‹ˆë‹¤!!</td>\n",
       "      <td>[ì•ìœ¼ë¡œ, ê¾¸ì¤€íˆ, ì´ê±¸ë¡œ, ì •ì°©í•´ì„œ, ë³€ë¹„íƒˆì¶œ, í•˜ë ¤ê³ , í•´ìš”, ã…ã…ë§Œì¡±í•©ë‹ˆë‹¤]</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review  \\\n",
       "0                             í•˜ë£¨ í•œí¬ ë³´ì¥ê· ìˆ˜ 20ì–µ ì¶©ë¶„í•œ ìœ ì‚°ê· !   \n",
       "1                                        ë¯¿ì„ ìˆ˜ ìˆëŠ” ë¸Œëœë“œ!   \n",
       "2                                 ì•„ì—°í•¨ìœ ë¡œ ë©´ì—­ë„ ì±™ê¸¸ ìˆ˜ ìˆì–´ìš”!   \n",
       "3                                        ëª¨ìœ  ìœ ë˜ ì›ë£Œ í•¨ìœ !   \n",
       "4   ì´ëŸ°ë¶„ê»˜ ì¶”ì²œ 1. ì„ì‹  ì¤‘ ë°°ë³€í™œë™ì´ ì›í™œí•˜ì§€ ì•Šì€ ë¶„ 2. ë³µë¶€ë¶ˆí¸ê°ê³¼ ë³€ë¹„ë¡œ ...   \n",
       "5                          ë²Œì¨ ë§Œì‚­ì„ í–¥í•´ê°€ëŠ” ì™€ì´í”„ë¥¼ ìœ„í•´ ì£¼ë¬¸í–ˆì–´ìš”.   \n",
       "6    ìš”ì¦˜ í™”ì¥ì‹¤ë„ ìì£¼ ëª»ê°€ê³ <br>ë”ë¶€ë£© í•˜ë‹¤ê³  í•˜ë”ë¼êµ¬ìš”. ì„ì‚°ë¶€ëŠ” ìœ ì‚°ê· ì´ í•„ìˆ˜...   \n",
       "7   í•˜ë‚˜ì”© íœ´ëŒ€í•˜ê¸°ë„ ì¢‹ê²Œ ë˜ì–´ìˆì–´ì„œ ì—¬í–‰ì´ë‚˜ ì™¸ì¶œí• ë•Œ ì£¼ë¨¸ë‹ˆì— ì™ì™ ì±™ê²¨ë‹¤ë‹ˆê¸° ì¢‹ì•˜ë‹µë‹ˆë‹¤.   \n",
       "8   ì•Œì•½ íƒ€ì…ì´ ì•„ë‹Œ ë¶„ë§í˜•ì´ë¼ì„œ ë¬¼ ì—†ì´ ê·¸ëƒ¥ í†¡ í„¸ì–´ë„£ê¸°ì—ë„ ì¥ì†Œì œì•½ë„ ì—†ê³  ë¶€ë‹´ì´...   \n",
       "9                          ì•„ì—°ë„ ë“¤ì–´ìˆì–´ì„œ ë” ê±´ê°•í•´ì§€ëŠ” ëŠë‚Œì´ì—ìš” ã…ã…   \n",
       "10                                     ë¯¿ê³  ë¨¹ì„ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤!   \n",
       "11             ì•ìœ¼ë¡œ ê¾¸ì¤€íˆ ì´ê±¸ë¡œ ì •ì°©í•´ì„œ ë³€ë¹„íƒˆì¶œ í•˜ë ¤ê³  í•´ìš” ã…ã…ë§Œì¡±í•©ë‹ˆë‹¤!!   \n",
       "\n",
       "                                               tokens  word_count  vocab_count  \n",
       "0                       [í•˜ë£¨, í•œí¬, ë³´ì¥ê· ìˆ˜, 20ì–µ, ì¶©ë¶„í•œ, ìœ ì‚°ê· ]           6            6  \n",
       "1                                    [ë¯¿ì„, ìˆ˜, ìˆëŠ”, ë¸Œëœë“œ]           4            4  \n",
       "2                            [ì•„ì—°í•¨ìœ ë¡œ, ë©´ì—­ë„, ì±™ê¸¸, ìˆ˜, ìˆì–´ìš”]           5            5  \n",
       "3                                    [ëª¨ìœ , ìœ ë˜, ì›ë£Œ, í•¨ìœ ]           4            4  \n",
       "4   [ì´ëŸ°ë¶„ê»˜, ì¶”ì²œ, 1, ì„ì‹ , ì¤‘, ë°°ë³€í™œë™ì´, ì›í™œí•˜ì§€, ì•Šì€, ë¶„, 2, ë³µë¶€...          20           19  \n",
       "5                    [ë²Œì¨, ë§Œì‚­ì„, í–¥í•´ê°€ëŠ”, ì™€ì´í”„ë¥¼, ìœ„í•´, ì£¼ë¬¸í–ˆì–´ìš”]           6            6  \n",
       "6   [ìš”ì¦˜, í™”ì¥ì‹¤ë„, ìì£¼, ëª»ê°€ê³ , br, ë”ë¶€ë£©, í•˜ë‹¤ê³ , í•˜ë”ë¼êµ¬ìš”, ì„ì‚°ë¶€ëŠ”,...          15           15  \n",
       "7   [í•˜ë‚˜ì”©, íœ´ëŒ€í•˜ê¸°ë„, ì¢‹ê²Œ, ë˜ì–´ìˆì–´ì„œ, ì—¬í–‰ì´ë‚˜, ì™¸ì¶œí• ë•Œ, ì£¼ë¨¸ë‹ˆì—, ì™ì™, ...          10           10  \n",
       "8   [ì•Œì•½, íƒ€ì…ì´, ì•„ë‹Œ, ë¶„ë§í˜•ì´ë¼ì„œ, ë¬¼, ì—†ì´, ê·¸ëƒ¥, í†¡, í„¸ì–´ë„£ê¸°ì—ë„, ì¥ì†Œ...          14           14  \n",
       "9                   [ì•„ì—°ë„, ë“¤ì–´ìˆì–´ì„œ, ë”, ê±´ê°•í•´ì§€ëŠ”, ëŠë‚Œì´ì—ìš”, ã…ã…]           6            6  \n",
       "10                                 [ë¯¿ê³ , ë¨¹ì„, ìˆ˜, ìˆì—ˆìŠµë‹ˆë‹¤]           4            4  \n",
       "11      [ì•ìœ¼ë¡œ, ê¾¸ì¤€íˆ, ì´ê±¸ë¡œ, ì •ì°©í•´ì„œ, ë³€ë¹„íƒˆì¶œ, í•˜ë ¤ê³ , í•´ìš”, ã…ã…ë§Œì¡±í•©ë‹ˆë‹¤]           8            8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e415fe",
   "metadata": {},
   "source": [
    "## **í…ìŠ¤íŠ¸ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤ìŠµ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2b079182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¬¸ì ìˆ˜: 26\n",
      "í† í° ë¦¬ìŠ¤íŠ¸: ['ì˜¤ëŠ˜ì€', 'íŒŒì´ì¬', 'í…ìŠ¤íŠ¸', 'ë¶„ì„ì„', 'ë°°ìš°ëŠ”', 'ì²«ë‚ ì…ë‹ˆë‹¤.']\n",
      "í† í° ìˆ˜: 6\n",
      "ì–´íœ˜ í¬ê¸°: 6\n",
      "ê°€ì¥ ê¸´ í† í°: ì²«ë‚ ì…ë‹ˆë‹¤. | ê¸¸ì´: 6\n"
     ]
    }
   ],
   "source": [
    "# (1) ê¸°ë³¸ ë¬¸ì¥ ì‹¤ìŠµ\n",
    "s = \"ì˜¤ëŠ˜ì€ íŒŒì´ì¬ í…ìŠ¤íŠ¸ ë¶„ì„ì„ ë°°ìš°ëŠ” ì²«ë‚ ì…ë‹ˆë‹¤.\"\n",
    "tokens = s.split()\n",
    "vocab = set(tokens)\n",
    "longest = max(tokens, key=len)\n",
    "\n",
    "print(\"ë¬¸ì ìˆ˜:\", len(s))\n",
    "print(\"í† í° ë¦¬ìŠ¤íŠ¸:\", tokens)\n",
    "print(\"í† í° ìˆ˜:\", len(tokens))\n",
    "print(\"ì–´íœ˜ í¬ê¸°:\", len(vocab))\n",
    "print(\"ê°€ì¥ ê¸´ í† í°:\", longest, \"| ê¸¸ì´:\", len(longest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1ae1d456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: ì™€ìš°!!! íŒŒì´ì¬ ë„ˆë¬´ ì¬ë°Œì–´ìš” ğŸ˜ŠğŸ˜Š  1234\n",
      "After : ì™€ìš° íŒŒì´ì¬ ë„ˆë¬´ ì¬ë°Œì–´ìš” 1234\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# (1) í…ìŠ¤íŠ¸ ì •ì œ í•¨ìˆ˜\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()                            # ì†Œë¬¸ì ë³€í™˜\n",
    "    text = re.sub(r\"[^ã„±-ã…ê°€-í£a-z0-9 ]\", \"\", text)     # í•œê¸€Â·ì˜ë¬¸Â·ìˆ«ì ì™¸ ì œê±°\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()             # ê³µë°± ì •ë¦¬\n",
    "    return text\n",
    "\n",
    "# (2) í…ŒìŠ¤íŠ¸\n",
    "s = \"ì™€ìš°!!! íŒŒì´ì¬ ë„ˆë¬´ ì¬ë°Œì–´ìš” ğŸ˜ŠğŸ˜Š  1234\"\n",
    "print(\"Before:\", s)\n",
    "print(\"After :\", clean_text(s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2ead2140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: (149993, 3)\n",
      "        id                           review  rating\n",
      "0  9324809       ë°°ìš°ë“¤ì˜ ì¸ìƒì—°ê¸°ê°€ ë‹ë³´ì˜€ë˜... ìµœê³ ì˜ ë“œë¼ë§ˆ       1\n",
      "1  9305425              ì•„ í˜œë¦¬ ë³´ê³ ì‹¶ë‹¤ ... ì—¬êµ°ì¢€ ã…        0\n",
      "2  5239110  ëˆˆì´ íŒ…íŒ…..... ì •ë§ ,..... ëŒ€ë°•ì´ë‹¤......       1\n",
      "3  9148159                 ìºìŠ¬ë¦° í„°ë„ˆì˜ ë³´ë””ëŠ” ë³¼ë§Œí–ˆë‹¤       0\n",
      "4  6144938                         ì§„ì§œ ìµœê³ ì˜€ë‹¤.       1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ë°ì´í„° ê²½ë¡œ\n",
    "path = \"nsmc_train.csv\"\n",
    "\n",
    "# ì¸ì½”ë”© ë¬¸ì œ ëŒ€ë¹„ (UTF-8 â†’ CP949 ìˆœì°¨ ì‹œë„)\n",
    "try:\n",
    "    df = pd.read_csv(path, encoding=\"utf-8\")\n",
    "except:\n",
    "    df = pd.read_csv(path, encoding=\"cp949\")\n",
    "\n",
    "print(\"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ:\", df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f75a8edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ê²°ì¸¡ì¹˜ ì œê±° í›„: (149993, 3)\n",
      "        id                           review  rating\n",
      "0  9324809       ë°°ìš°ë“¤ì˜ ì¸ìƒì—°ê¸°ê°€ ë‹ë³´ì˜€ë˜... ìµœê³ ì˜ ë“œë¼ë§ˆ       1\n",
      "1  9305425              ì•„ í˜œë¦¬ ë³´ê³ ì‹¶ë‹¤ ... ì—¬êµ°ì¢€ ã…        0\n",
      "2  5239110  ëˆˆì´ íŒ…íŒ…..... ì •ë§ ,..... ëŒ€ë°•ì´ë‹¤......       1\n"
     ]
    }
   ],
   "source": [
    "# í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ìë™ íƒìƒ‰\n",
    "text_col = 'review'\n",
    "for c in df.columns:\n",
    "    if 'review' in c.lower() or 'document' in c.lower() or 'text' in c.lower():\n",
    "        text_col = c\n",
    "        break\n",
    "if text_col is None:\n",
    "    text_col = df.columns[0]\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ì œê±°\n",
    "df = df.dropna(subset=[text_col]).copy()\n",
    "df[text_col] = df[text_col].astype(str).str.strip()\n",
    "\n",
    "print(\"âœ… ê²°ì¸¡ì¹˜ ì œê±° í›„:\", df.shape)\n",
    "print(df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bf7e5c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            review                  cleaned\n",
      "0       ë°°ìš°ë“¤ì˜ ì¸ìƒì—°ê¸°ê°€ ë‹ë³´ì˜€ë˜... ìµœê³ ì˜ ë“œë¼ë§ˆ  ë°°ìš°ë“¤ì˜ ì¸ìƒì—°ê¸°ê°€ ë‹ë³´ì˜€ë˜ ìµœê³ ì˜ ë“œë¼ë§ˆ\n",
      "1              ì•„ í˜œë¦¬ ë³´ê³ ì‹¶ë‹¤ ... ì—¬êµ°ì¢€ ã…             ì•„ í˜œë¦¬ ë³´ê³ ì‹¶ë‹¤ ì—¬êµ°ì¢€\n",
      "2  ëˆˆì´ íŒ…íŒ…..... ì •ë§ ,..... ëŒ€ë°•ì´ë‹¤......            ëˆˆì´ íŒ…íŒ… ì •ë§ ëŒ€ë°•ì´ë‹¤\n",
      "3                 ìºìŠ¬ë¦° í„°ë„ˆì˜ ë³´ë””ëŠ” ë³¼ë§Œí–ˆë‹¤         ìºìŠ¬ë¦° í„°ë„ˆì˜ ë³´ë””ëŠ” ë³¼ë§Œí–ˆë‹¤\n",
      "4                         ì§„ì§œ ìµœê³ ì˜€ë‹¤.                  ì§„ì§œ ìµœê³ ì˜€ë‹¤\n"
     ]
    }
   ],
   "source": [
    "# clean_text í•¨ìˆ˜ ì¬ì‚¬ìš©\n",
    "df[\"cleaned\"] = df[text_col].apply(clean_text)\n",
    "print(df[[\"review\", \"cleaned\"]].head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1ac53d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ê¸°ë³¸ í†µê³„\n",
      "            char_len    token_count     vocab_size\n",
      "count  149993.000000  149993.000000  149993.000000\n",
      "mean       32.608622       7.519078       7.405852\n",
      "std        28.234004       6.493032       6.312439\n",
      "min         0.000000       0.000000       0.000000\n",
      "25%        14.000000       3.000000       3.000000\n",
      "50%        24.000000       6.000000       6.000000\n",
      "75%        39.000000       9.000000       9.000000\n",
      "max       140.000000      42.000000      40.000000\n"
     ]
    }
   ],
   "source": [
    "# í† í°í™” ë° í†µê³„ ê³„ì‚°\n",
    "df[\"tokens\"] = df[\"cleaned\"].apply(lambda x: x.split())\n",
    "df[\"token_count\"] = df[\"tokens\"].apply(len)\n",
    "df[\"vocab_size\"] = df[\"tokens\"].apply(lambda x: len(set(x)))\n",
    "df[\"char_len\"] = df[\"cleaned\"].apply(len)\n",
    "\n",
    "# ê°„ë‹¨í•œ í†µê³„ ìš”ì•½\n",
    "print(\"âœ… ê¸°ë³¸ í†µê³„\")\n",
    "print(df[[\"char_len\", \"token_count\", \"vocab_size\"]].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eeaf8af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ì™„ë£Œ: nsmc_train_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# ê²°ê³¼ íŒŒì¼ ì €ì¥\n",
    "save_path = \"nsmc_train_cleaned.csv\"\n",
    "df[[\"cleaned\", \"token_count\", \"vocab_size\", \"char_len\"]].to_csv(save_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"ğŸ’¾ ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ì™„ë£Œ:\", save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739e78da",
   "metadata": {},
   "source": [
    "### ì¶”ê°€ ê³¼ì œ(ì„ íƒ)\n",
    "\n",
    "1. `token_count`ê°€ 30ê°œ ì´ìƒì¸ ë¦¬ë·°ë§Œ í•„í„°ë§í•´ ìƒˆë¡œìš´ CSVë¡œ ì €ì¥\n",
    "2. `vocab_size` í‰ê· ë³´ë‹¤ ë†’ì€ ë¦¬ë·°ë§Œ ì¶”ì¶œí•´ë³´ê¸°\n",
    "3. ì „ì²´ ë°ì´í„°ì—ì„œ ê°€ì¥ ìì£¼ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ Top 20 ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "631d58bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… token_count â‰¥ 30ì¸ ë¦¬ë·° ìˆ˜: 2628\n",
      "                                               cleaned  token_count\n",
      "46   ì´ê±° ë‚´ìš©ì˜ 80í”„ë¡œê°€ ê±°ì§“ê³¼ ê³¼ì¥ì…ë‹ˆë‹¤ ì˜ˆë¥¼ ë“¤ì–´ í•˜ë‚˜ë©´ ì–˜ê¸°í•˜ìë©´ ì´ì†Œë£¡ì´ ì˜ì¶˜...           32\n",
      "98   ì°¨ë¼ë¦¬ ì”ì”í•œ ëª©ì†Œë¦¬ë¡œ ë”ë¹™ì„ í–ˆìœ¼ë©´ ë‹¤íë¼ë„ ë³´ëŠ” ëŠë‚Œìœ¼ë¡œ ë´¤ì„í…ë°ì´ê±´ ë­ ë½€ë¡œë¡œ...           30\n",
      "473  ì™€ ì§„ì§œ ì¬ë¯¸ì—†ë‹¤ ì—°ê¸° ëŒ€ì‚¬ ì—°ì¶œ ëª¨ì¡°ë¦¬ ìµœì•… ë¨¸ ì´ëŸ° ì˜í™”ê°€ ë‹¤ ìˆì§€ í‰ì ì— ì†ì•„...           36\n",
      "596  ê¼¬ë¦¬ì— ê¼¬ë¦¬ë¥¼ ë¬´ëŠ” ë³µìˆ˜ê·¹ì´ë¼ëŠ” ì‹œë‚˜ë¦¬ì˜¤ê°€ ìƒë‹¹íˆ ë…íŠ¹í•˜ë©´ì„œë„ í¥ë¯¸ë¡­ë‹¤ ì”ì¸í•œ ì¥ë©´...           31\n",
      "642  ì•„ì£¼ ì§€ë£¨í•˜ê³  ì¬ë¯¸ë„ ì—†ëŠ” ê·¸ëƒ¥ ì¡°ì¡° ì¼ìƒì˜ ë‹¤íë¥¼ ë³´ëŠ” ëŠë‚Œ ê´€ìš°ê°€ ì£½ê³  ë‚˜ì„œ ì¡°...           31\n"
     ]
    }
   ],
   "source": [
    "tc_30 = df[df[\"token_count\"] >= 30]\n",
    "print(f\"âœ… token_count â‰¥ 30ì¸ ë¦¬ë·° ìˆ˜: {len(tc_30)}\")\n",
    "print(tc_30[[\"cleaned\", \"token_count\"]].head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0011520c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… vocab_size í‰ê· : 7.41\n",
      "âœ… í‰ê·  ì´ˆê³¼ ë¦¬ë·° ìˆ˜: 51888\n",
      "                                          cleaned  vocab_size\n",
      "5              ì˜¤ì§€í˜¸ ì—°ê¸° ì§•ì±  ì˜ í•œë‹¤ ê·¸ë¦¬ê³  ì „íš¨ì„± ì‚´ì¸ì‚¬ê±´ ë¹¨ë¦¬ í’€ì—ˆìŒ          10\n",
      "7           ìƒì‹¤ì˜ ì‹œëŒ€ì™€ ë§ë¬¼ë ¤ ì°½ë°±í•˜ê²Œ í˜ëŸ¬ê°€ëŠ” ì²­ì¶˜ì˜ ê³µí—ˆí•¨ ë¦¬ë·°ì°¸ì¡°í•˜ì„¸ìš”           8\n",
      "11            ë„ˆë¬´ ì¬ë°Œê³  ê°ë™ ê·¸ë£¨ ì¸¤ë°ë ˆ ê·¸ë¦¬ê³  ë¯¸ë‹ˆì–¸ë“¤ ë„ˆë¬´ë„ˆë¬´ë„ˆë¬´ê·€ì—½ë‹¤           8\n",
      "12                  ì¤‘êµ­ì‚° ì§í‰ ëƒ„ìƒˆê°€ í’€í’€ ê·¸ë‚˜ë§ˆ ë¦°ì¦ˆë§ ë•Œë¬¸ì— ì°¸ëŠ”ë‹¤           8\n",
      "13  ì”ì¸í•˜ë‹¤ ê·¼ë° ê·¸ë¿ì´ë‹¤ ìê¾¸ ì½”ë¯¹ìš”ì†Œë¥¼ ì§‘ì–´ë„£ìœ¼ë ¤ê³  í•˜ëŠ” ì˜ë„ê°€ ë³´ì´ëŠ”ê±´ ë¬´ì—ˆì¼ê¹Œ          10\n"
     ]
    }
   ],
   "source": [
    "vocab_mean = df[\"vocab_size\"].mean()\n",
    "df_vocab_rich = df[df[\"vocab_size\"] > vocab_mean]\n",
    "\n",
    "print(f\"âœ… vocab_size í‰ê· : {vocab_mean:.2f}\")\n",
    "print(f\"âœ… í‰ê·  ì´ˆê³¼ ë¦¬ë·° ìˆ˜: {len(df_vocab_rich)}\")\n",
    "print(df_vocab_rich[[\"cleaned\", \"vocab_size\"]].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "74b13e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë‹¨ì–´ Top 20 (word, count)\n",
      "ì˜í™”              17865\n",
      "ë„ˆë¬´              8423\n",
      "ì •ë§              7959\n",
      "ì§„ì§œ              6372\n",
      "ì´               5113\n",
      "ì™œ               3342\n",
      "ë”               3295\n",
      "ì´ëŸ°              3274\n",
      "ê·¸ëƒ¥              3250\n",
      "ìˆ˜               2878\n",
      "ì˜í™”ë¥¼             2869\n",
      "ì˜               2695\n",
      "ë‹¤               2661\n",
      "ë³´ê³               2636\n",
      "ì¢€               2524\n",
      "ì˜í™”ëŠ”             2492\n",
      "ì˜í™”ê°€             2431\n",
      "ê·¸               2417\n",
      "ë³¸               2320\n",
      "ìµœê³ ì˜             2282\n"
     ]
    }
   ],
   "source": [
    "# ì „ì²´ í† í° ëª¨ìœ¼ê¸°\n",
    "all_tokens = []\n",
    "for ts in df[\"tokens\"]:\n",
    "    # ë¹ˆ ë¬¸ìì—´ë§Œ ì œì™¸ (ë„ë©”ì¸ ë¶ˆìš©ì–´ëŠ” ì•„ì§ ë°°ìš°ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ ìƒëµ)\n",
    "    all_tokens.extend([t for t in ts if t != \"\"])\n",
    "\n",
    "# ì§ì ‘ ë¹ˆë„ ì„¸ê¸°(ë”•ì…”ë„ˆë¦¬)\n",
    "freq = {}\n",
    "for w in all_tokens:\n",
    "    if w in freq:\n",
    "        freq[w] += 1\n",
    "    else:\n",
    "        freq[w] = 1\n",
    "\n",
    "# ë”•ì…”ë„ˆë¦¬ â†’ (ë‹¨ì–´, ë¹ˆë„) ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ í›„, ë¹ˆë„ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬\n",
    "items = list(freq.items())\n",
    "items.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "top20 = items[:20]\n",
    "\n",
    "print(\"âœ… ë‹¨ì–´ Top 20 (word, count)\")\n",
    "for w, c in top20:\n",
    "    print(f\"{w:<15} {c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f677cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
